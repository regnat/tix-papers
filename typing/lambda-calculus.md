### General description
\label{typing::lambda-calculus::general-description}

In this part, we consider a restriction of the language to a subset of itself
consisting of a lambda-calculus with typecase (i.e., we exclude lists and
records and all the related operations which will be dealt with in
\Cref{typing::structures}).

The type-system is divided into two parts: an "inference" system and a "check"
one.
The first one corresponds to classical bottom-up type inference while the
second one is a top-down system which does not do any inference but only tries
to check that an expression accepts a given type.
This double system is an extension of the use of type annotations in inference
algorithms which adds the possiblility of using them in a non-local way. This
result may be obtained in many languages by simply preprocessing the code and
trying to propagate the type annotations (that's for example what OCaml does in
order not to enforce the programmer to directly annotate the return type of a
pattern-matching on a GADT, but let him simply annotate for example the
top-level expression).
In Nix-light however, the presence of union and intersection types makes
certain expressions impossible to annotate because they will be given several
different types under different environments.

For example, consider the following expression:

```
let f =
  λcond.λx.
    (_ = cond tin true) ? x + 1 : not x
in f
```

We wish to give it the type `(true -> Int -> Int) AND (false -> Bool -> Bool)`.
This means that `x` must have the type `Int` if `cond` is `true`, and `Bool`
otherwise.
It is thus impossible to annotate − except by the type `Int AND Bool` which
equals `Empty`, or by the gradual type.

However, the *check* type-system allows to check − if we annotate `f` with the
type `(true -> Int -> Int) AND (false -> Bool -> Bool)` − to check that the
expression indeed admits both types `true -> Int -> Int` and `false -> Bool ->
Bool` (and thus the intersection of both).

### Typing of patterns

For the restriction of the language that we consider here, the only possible
patterns are `<var>` and `<var>:τ`.

\newcommand{\accept}[1]{\left\langle#1\right\rangle}
\newcommand{\tmatch}[2]{\sfrac{#2}{#1}}

We define two operators $\accept{p}$ and $\tmatch{τ}{p}$ which corresponds
respectively to the type accepted by a pattern $p$ (i.e., the type whose
interpretation is the set of values accepted by the pattern) and the typing
environment generated by the matching of a type $τ$ against the pattern $p$ by:

\begin{align*}
  \accept{x} &= \grad \\
  \accept{x:\tau} &= \tau
\end{align*}

and

\begin{align*}
  \tmatch{\tau}{x} &= x : \tau \\
  \tmatch{σ}{x:\tau} &= σ \wedge \tau
\end{align*}

By default (in the absence of annotation), the type accepted by a pattern is the
gradual type. This choice makes the type-system very permissive in the absence of
annotations.

### Typing rules

The judgement $Γ \tinfer e : τ$ corresponds to the *inference* system and
the judgement $Γ \tcheck e : τ$ to the *check* system.
The notation $Γ \tIC e : τ$ means either $Γ \tinfer e : τ$ or
$Γ \tcheck e : τ$ (but always the same in a given inference rule).

The rules for both systems are given in the
\Cref{typing::lambda-calculus}.

#### Constants and variables

\newcommand{\Bt}{\mathcal{B}}
We assume the existence of a function $\Bt$ which associates to each constant
$c$ its type $\Bt(c)$.

#### Lambda-abstractions

To *infer* the type of e lambda-abstraction $λp.e$ under the hypothesis $Γ$, we
first determine its domain which is the accepted type of the pattern $p$. Then
we compute its codomain, which is the type of the body $e$ under the
extra-hypothesis provided by the pattern.
These extra hypothesis is given by $\tmatch{\accept{p}}{p}$. Indeed,
$\accept{p}$ is by definition the most general type that the pattern accepts,
so this environment is the most general one under which we may have to type the
body.

The *check* is somehow more complex. The idea is that to check that an expression
$λ p.e$ admits the type $τ$ under the hypothesis $Γ$ we must check
that each arrow type $σ_1 \rightarrow σ_2$ "contained" in $τ$ is
admitted by the expression, which means that under the hypothesis $Γ;
\tmatch{σ_1}{p}$, $e$ admits the type $σ_2$.

\newcommand{\A}{\mathcal{A}}
To properly define this notion of "containment", we introduce the $\A$ operator
defined as follows for a type $τ$ subtype of `Empty -> Any`:

If $τ$ is of the form

\begin{displaymath}
  \tau = \bigvee\limits_{i\in I}\left(
    \bigwedge\limits_{p\in P_i} (σ_p \rightarrow \tau_p)
    \wedge \bigwedge\limits_{n \in N_i} \lnot (σ_n \rightarrow \tau_n)
  \right)
\end{displaymath}

then $\A(\tau)$ is defined as

\begin{displaymath}
  \A(\tau) = \bigsqcup\limits_{i \in I} \{ σ_p \rightarrow \tau_p | p \in P_i \}
\end{displaymath}

where $\sqcup$ is itself defined as

\begin{displaymath}
  \{ σ_i \rightarrow \tau_i \| i \in I \} \sqcup \{ σ_j \rightarrow \tau_j \| j \in J \} =
    \{ (σ_i \wedge σ_j) \rightarrow (\tau_i \vee \tau_j) \| i \in I, j \in J \}
\end{displaymath}

@Fri04 shows that $τ$ can always be expressed in previous form (in fact this
possibility is fundamental for the sybtyping algorithm as shown by @Cas15).

In the example of \Cref{typing::lambda-calculus::general-description}
the type $τ$ is equal to `(true -> Int -> Int) AND (false -> Bool -> Bool)`,
so $\A(\tau)$ is the set $\{$ `true -> Int -> Int`; `false -> Bool -> Bool` $\}$.

#### Application

\newcommand{\dom}{\tilde{\operatorname{Dom}}}
\newcommand{\image}{\tilde{\circ}}

The inference rule for the application is different from the one used in simply
typed lambda-calculus: Because of the presence of union and intersection types,
the types of functions are not simply arrow types, but are all the subtypes of
the `Empty -> Any` type.
As consequence, the definitions of the domain and image of such function
types is more complex.

We reuse the definitions of the $\dom$ and $\image$ operators defined by @CL17.
The intuition for these operators is that $\dom(τ)$ is the domain of the
functions of type $τ$ and $τ \image σ$ is the image by $τ$ of all the
elements of type $σ$.
For example, $\dom(τ_1 \rightarrow σ_1 \wedge τ_2 \rightarrow σ_2)$ is
$τ_1 \vee τ_2$, and $(τ_1 \rightarrow σ_1 \wedge τ_2 \rightarrow
σ_2) \image τ_1$ is $σ_1$ (provided that $σ_1 \wedge σ_2 = \Empty$).
Once these operators are defined, the inference rule for the application is
rather straightforward.

The *check* rule is simpler, but requires using the inference system, as the type
of the argument is unknown.
Hence, to check that $Γ \tcheck e_1 e_2 : τ$, we first *infer* the type
$σ$ of $e_2$, and then we check that $e_1$ has type $σ \rightarrow
τ$.
We also could imagine first inferring the type $τ'$ of $e_1$, and then
try to calculate the preimage $σ'$ of $τ$ by $τ'$ and check that $e_2$
has type $σ'$. However, this approach is more complicated (it is unsure
whether there is an easy way to calculate this preimage) and probably less
useful in practice (as inferring the type of functions is often the difficult
part while checking it is easier).

#### Let-bindings

The let-bindings are the places where the system goes from inference to
checking: for each variable that is being defined, if it is annotated, then we
*check* that its definition has the right type (else we simply *infer* the type
of
its definition).
As let-bindings are recursive and no unification is made, the non-annotated
variables must be given a default type to type the definitions. The chosen type
is `?` (although choosing `Any` instead is an equally reasonable choice, simply
more restrictive as for instance an expression of type `?` can be the argument
of any function (because `?` is a gradual subtype of every other type) while an
expression of type `Any` can only be the argument of a function whose domain is
`Any` or `?`).
This rule has the advantage of being quite general. In particular it can type
non-recursive let-bindings without requiring annotations and without loss of
precision.

#### Typecase

The typing of the typecase uses *occurrence typing*.
This means that when typing the expression `(x = e tin t) ? e1 : e2`, the type
of `x` will be refined in each branch: its occurrences will be assumed
to be of type `$t_e$ AND t` in `e1` and of type `$t_e$ AND $\lnot$t` in `e2`
(where `$t_e$` is the type of `e`).
Moreover, if the system infers that `e` is always of type `t` (or `$\lnot$t`),
then the dead branch does not need to be typed.
This is what the two implications in the inference rule express: If one of the
two conditions will never be met (or both), then there is no need to type the
corresponding branch.
This particular characteristic may seem undesirable (as it in particular that
an expression may be well-typed while some of its sub-terms are not), but the
need for it is clear if we once again consider the example of
\Cref{typing::lambda-calculus::general-description}.
Indeed, we want the body of the function to be well-typed under the hypothesis
`cond: True; x : Int`, while `not x` is not (but is never reached under those
hypothesis).
One last particularity is that both branches may have different types, the
final type being the union of them.
For example, we want to accept the expression `(x = e tin Int) ? x : not x`
although the then-branch is of type `Int` and the else-branch of type `Bool`.
Of course, it may be the case that the fact that the two branches have two
different types is an error, in which case the type error will probably occur
anyway, but at the place where the result of this expression is used rather
than at the place of its definition, which is unfortunate.

The check works the same way, except that we can directly check the same type
for both branches. Note that we have to infer the type of the tested
expression since we can not know it in advance.

\input{typing/lambda-inference-rules.tex}
